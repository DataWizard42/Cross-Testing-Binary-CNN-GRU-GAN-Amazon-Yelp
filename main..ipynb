{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGfW76uJX4tr",
        "outputId": "f102a4ee-c154-480a-bd63-5c56ad786dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.10/dist-packages (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch) (2.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import re\n",
        "import tqdm\n",
        "import unicodedata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekvGq3a8YO66",
        "outputId": "4b1d2120-d968-4087-bc27-c96216b1265e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import GRU, Embedding, Flatten, Input, Dense, LeakyReLU, BatchNormalization, Reshape\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "seed = 3541\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "def date_time(x):\n",
        "    if x == 1:\n",
        "        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
        "    if x == 2:\n",
        "        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
        "    if x == 3:\n",
        "        return 'Date now: %s' % datetime.datetime.now()\n",
        "    if x == 4:\n",
        "        return 'Date today: %s' % datetime.date.today()"
      ],
      "metadata": {
        "id": "1BH5Q_ROYoqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    [s.extract() for s in soup(['iframe', 'script'])]\n",
        "    stripped_text = soup.get_text()\n",
        "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "    return stripped_text\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "def pre_process_corpus(docs):\n",
        "    norm_docs = []\n",
        "    for doc in tqdm.tqdm(docs):\n",
        "        doc = strip_html_tags(doc)\n",
        "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "        doc = doc.lower()\n",
        "        doc = remove_accented_chars(doc)\n",
        "        doc = contractions.fix(doc)\n",
        "\n",
        "        doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        doc = doc.strip()\n",
        "        norm_docs.append(doc)\n",
        "\n",
        "    return norm_docs"
      ],
      "metadata": {
        "id": "cf_p6Bl5YvI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelAmazon = keras.models.load_model('/content/Binary_Classification_86_Amazon_Reviews_CNN.h5')\n",
        "\n",
        "\n",
        "modelYelp = keras.models.load_model('/content/Binary_Classification_90_Yelp_Reviews_CNN.h5')\n",
        "\n",
        "\n",
        "dataset_test_yelp = pd.read_csv('/content/yelp_test.csv')\n",
        "\n",
        "\n",
        "dataset_test_Amazon = pd.read_csv('/content/amazon_test.csv')\n",
        "\n",
        "dataset_train_Amazon = pd.read_csv('/content/amazon_review_sa_binary_csv/train.csv')\n"
      ],
      "metadata": {
        "id": "oGpUVYkrkTsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_Amazon = dataset_train_Amazon.iloc[:100,:]\n",
        "\n",
        "test_Amazon = test_Amazon.iloc[:38000,:]\n"
      ],
      "metadata": {
        "id": "dt1ZTq5XkYVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking only necessary columns\n",
        "X_test_yelp = test_yelp['review_text'].values\n",
        "y_test_yelp = test_yelp['class_index'].values\n",
        "X_test_Amazon = test_Amazon['review_text'].values\n",
        "y_test_Amazon = test_Amazon['class_index'].values\n",
        "X_train_Amazon = train_Amazon['review_text'].values\n",
        "y_train_Amazon = train_Amazon['class_index'].values\n",
        "X_M_data = M_data['review_text'].values\n",
        "y_M_data = M_data['class_index'].values\n"
      ],
      "metadata": {
        "id": "UxdUHUPMkdn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the Data\n",
        "X_test_yelp = pre_process_corpus(X_test_yelp)\n",
        "X_test_Amazon = pre_process_corpus(X_test_Amazon)\n",
        "X_train_Amazon = pre_process_corpus(X_train_Amazon)\n",
        "X_M_data = pre_process_corpus(X_M_data)\n"
      ],
      "metadata": {
        "id": "GhyxpYhokf8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and Fitting the Tokenizer\n",
        "t = Tokenizer(oov_token='<UNK>')\n",
        "t.fit_on_texts(X_train_Amazon)\n",
        "t.word_index['<PAD>'] = 0"
      ],
      "metadata": {
        "id": "nwQ8oXN2kguq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming text to sequences\n",
        "X_test_yelp = t.texts_to_sequences(X_test_yelp)\n",
        "X_test_Amazon = t.texts_to_sequences(X_test_Amazon)\n",
        "X_train_Amazon = t.texts_to_sequences(X_train_Amazon)\n",
        "X_M_data = t.texts_to_sequences(X_M_data)\n"
      ],
      "metadata": {
        "id": "rVk9J7JLkjx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the transformed text (sentences) to maximum length of 220\n",
        "X_test_yelp = sequence.pad_sequences(X_test_yelp, maxlen=220)\n",
        "X_test_Amazon = sequence.pad_sequences(X_test_Amazon, maxlen=220)\n",
        "X_train_Amazon = sequence.pad_sequences(X_train_Amazon, maxlen=220)\n",
        "X_M_data = sequence.pad_sequences(X_M_data, maxlen=220)\n"
      ],
      "metadata": {
        "id": "F-9577LvklrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and Fitting the label encoder\n",
        "le = LabelEncoder()\n",
        "num_classes=2\n",
        "y_train_Amazon = le.fit_transform(y_train_Amazon)\n"
      ],
      "metadata": {
        "id": "SxVPf4llkuLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming the labels\n",
        "y_test_yelp = le.transform(y_test_yelp)\n",
        "y_test_Amazon = le.transform(y_test_Amazon)\n",
        "y_M_data = le.transform(y_M_data)"
      ],
      "metadata": {
        "id": "vvukY_Vekvs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the models\n",
        "# Testing Amazon Classifier on Yelp Test Data\n",
        "print(\"Testing Amazon Classifier on Yelp Test Data\")\n",
        "scores = modelAmazon.evaluate(X_test_yelp, y_test_yelp, verbose=1)\n",
        "print(\"Accuracy: %.2f%% /n\" % (scores[1]*100))\n"
      ],
      "metadata": {
        "id": "TgYGpwx8k1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Amazon Classifier on Amazon Test Data\n",
        "print(\" Testing Yelp Classifier on Amazon Test Data\")\n",
        "scores = modelAmazon.evaluate(X_test_Amazon, y_test_Amazon, verbose=1)\n",
        "print(\"Accuracy: %.2f%% /n\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "owvnVFGkk3yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Yelp Classifier on Yelp Test Data\n",
        "print(\" Testing Yelp Classifier on Yelp Test Data\")\n",
        "scores = modelYelp.evaluate(X_test_yelp, y_test_yelp, verbose=1)\n",
        "print(\"Accuracy: %.2f%%  \" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "30s-fV99k53v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Yelp Classifier on Amazon Test Data\n",
        "print(\" Testing Yelp Classifier on Amazon Test Data\")\n",
        "scores = modelYelp.evaluate(X_test_Amazon, y_test_Amazon, verbose=1)\n",
        "print(\"Accuracy: %.2f%% \" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "ldTJZpGYk9SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on manual Data\n",
        "# Testing Yelp Classifier on Manually Inputted Reviews\n",
        "print(\" Testing Yelp Classifier on Manually Inputted Reviews \")\n",
        "scores = modelYelp.evaluate(X_M_data, y_M_data, verbose=1)\n",
        "print(\"Accuracy: %.2f%% \" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "zOevrVdilBZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zlqFUqBjglCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Testing Yelp Classifier on Manually Inputted Reviews\n",
        "print(\" Testing Yelp Classifier on Manually Inputted Reviews\")\n",
        "scores = modelAmazon.evaluate(X_M_data, y_M_data, verbose=1)\n",
        "print(\"Accuracy: %.2f%% \" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "z7tVxgpilDqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}